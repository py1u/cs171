{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 171 / EE 142 Problem Set 2\n",
    "# Due Friday, February 9, 2024 @ 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read *all* cells carefully and answer all parts (both text and missing code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your information below:\n",
    "\n",
    "<div style=\"color: #000000;background-color: #EEEEFF\">\n",
    "    Your Name (submitter): Peter Lu <br>\n",
    "Your student ID (submitter): #########\n",
    "    \n",
    "<b>By submitting this notebook, I assert that the work below is my own work, completed for this course.  Except where explicitly cited, none of the portions of this notebook are duplicated from anyone else's work or my own previous work.</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <font size=+2>Total Problem Set Grading</font> (to be completed by grader)<br>\n",
    "    Total Points: /20<br>\n",
    "    Late Days Used on this Assignment: <br>\n",
    "    Total Late Days Used: <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFEEDD\">\n",
    "<h2>Overview</h2>\n",
    "\n",
    "In this problem set, we will revisit the same movie review data from last time.  We will first try to predict the numeric score of the review (regression) using linear regression (problem 1).  Then, we will try to just predict whether it is a good review or bad review (problem 2).  Finally, we will consider feature selection (problems 3-5).\n",
    "\n",
    "The code below imports all allowed libraries and loads the data.  The variables loaded are as follows\n",
    "- Training data:\n",
    "    - `trainX` the data matrix, as is standard.  Each feature is a little different from last time.  The ith feature corresponds to the ith most common word across all reviews.  It is still related to the number of times the word is used in the review.  However, instead of bucketing this number into a category, we use the real value. Except, instead of the raw count, we record the number of standard deviations this raw count is away from the mean raw count.  This is called z-score normalizing the data.  So, if the value is 0, then this review uses this word the average number of times.  If the value is +1, this review uses this word one standard deviation more than average.  If -1, it uses it one standard deviation less than average.\n",
    "    - `trainYreg` the regression prediction values.  We don't predict the raw rating (from 0 to 10), but rather the difference of this raw rating and 5.  So if the value in this vector is +3, that means the rating was an 8.  If the value is -4, the actual rating was a 1.\n",
    "    - `trainYclass` the classification prediction values.  These are +1 for positive reviews and -1 for negative reviews, same as last time.\n",
    "- Testing data:\n",
    "    - `testX` same as `trainX` but for the testing set\n",
    "    - `testYreg` same as `trainYreg` but for the testing set\n",
    "    - `testYclass` same as `trainYclass` but for the testing set\n",
    "    \n",
    "Note that the X matrices have the \"column of all ones\" (or the constant feature) <b>already added</b> as the zeroth column.\n",
    "\n",
    "For this problem set, we will only use 5000 training points to simulate a small-data problem (this also speeds up some computations).  You *may* wish to (outside of this problem) see how the results change if you use all 25000 training data points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no other libraries are to be imported!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "# load the data (this time from a \"sparse data format\"\n",
    "# that is smaller and loads faster\n",
    "def loadsparsedata(fn):\n",
    "    \n",
    "    fp = open(fn,\"r\")\n",
    "    lines = fp.readlines()\n",
    "    maxf = 0;\n",
    "    for line in lines:\n",
    "        for i in line.split()[1::2]:\n",
    "            maxf = max(maxf,int(i))\n",
    "    \n",
    "    X = np.zeros((len(lines),maxf))\n",
    "    Y = np.zeros((len(lines)))\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        values = line.split()\n",
    "        Y[i] = int(values[0])\n",
    "        for j,v in zip(values[1::2],values[2::2]):\n",
    "            X[i,int(j)-1] = int(v)\n",
    "    \n",
    "    X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "    rs = np.random.RandomState(seed=8675309)\n",
    "    rs.shuffle(X)\n",
    "    rs = np.random.RandomState(seed=8675309)\n",
    "    rs.shuffle(Y)\n",
    "    return X,Y\n",
    "\n",
    "def loadplusones(fn):\n",
    "    (X,Y) = loadsparsedata(fn)\n",
    "    X = np.column_stack((np.ones(X.shape[0]),X))\n",
    "    return X,Y\n",
    "\n",
    "(trainX,trainYreg) = loadplusones('/usr/local/cs171/sptrainreal.txt')\n",
    "# below two lines limit the data to only 5000 training examples\n",
    "trainX = trainX[:5000,:]\n",
    "trainYreg = trainYreg[:5000]\n",
    "(testX,testYreg) = loadplusones('/usr/local/cs171/sptestreal.txt')\n",
    "trainYreg = trainYreg - 5\n",
    "testYreg = testYreg - 5\n",
    "trainYclass = np.sign(trainYreg)\n",
    "testYclass = np.sign(testYreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFEEFF\">\n",
    "    <font size=+2>Part I: Linear Regression</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "    <font size=+2>Question 1:</font> <font size=+1>(3 points)</font>\n",
    "Complete the training and testing functions below for linear least squares.</div>\n",
    "<div class=\"alert alert-success\">\n",
    "    <font size=+1>Grading</font> (to be completed by grader)<br>\n",
    "    Score: /3<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnlls(X,Y):\n",
    "    # X is the data matrix of shape (m,n)\n",
    "    # Y is are the target values of shape (m,)\n",
    "    # function should return w of shape (n,)\n",
    "\n",
    "    # your code here\n",
    "    \n",
    "def predictlls(X,w):\n",
    "    # X is the (testing) data of shape (m,n)\n",
    "    # w are the weights learned in linear least-squares regression of shape (n,)\n",
    "    # function should return Y, the predicted values of shape (m,)\n",
    "\n",
    "    # your code here\n",
    "    \n",
    "def testlls(X,Y,w):\n",
    "    # X and Y are the testing data\n",
    "    # w are the weights from linear least-squares regression\n",
    "    # returns the mean squared errorv\n",
    "    Ydelta = Y - predictlls(X,w)\n",
    "    return (Ydelta*Ydelta).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now code to check the training and testing errors:\n",
    "wreg = learnlls(trainX,trainYreg)\n",
    "print('training mean squared error: ',testlls(trainX,trainYreg,wreg))\n",
    "print('testing mean squared error:  ',testlls(testX,testYreg,wreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFEEFF\">\n",
    "    <font size=+2>Part II: Logistic Regression</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "    <font size=+2>Question 2:</font> <font size=+1>(8 points)</font>\n",
    "    \n",
    "Okay, now we will do the same for classification using logistic regression.\n",
    "    \n",
    "Complete the training and testing functions below for logistic regression.  We will use a constant step size of $10^{-5}$.  Picking a good step size is tricky, but this one should work well for this assignment.  Start $w$ at 0 (yes, sometimes this isn't a good choice, but for logistic regression, it is fine).  Use **batch** (or standard) gradient descent.  (Stochastic gradient descent is harder to tell whether it is converging.)  Stop when the *total loss* function does not improve by more than 0.1 after a step.\n",
    "    \n",
    "A few hints:\n",
    "- This function will need to be written without loops over data examples to be fast enough for the next part (my code takes under a minute to execute the training and testing error cell, below).\n",
    "- You can use `print` to output debugging information (or even use pyplot to plot things!).  The line `clear_output(wait=True)` will clear the output, in case you don't want the cell's output to extend too far during debugging.  (please remove debugging output when submitting)\n",
    "- To check to see if it is working, you should look that the gradient is getting smaller, but (more importantly) that the objective function (the loss) is getting smaller.\n",
    "\n",
    "</div>\n",
    "   <div class=\"alert alert-success\">\n",
    "    <font size=+1>Grading</font> (to be completed by grader)<br>\n",
    "    Score: /8<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnlogreg(X,Y):\n",
    "    # X is the data matrix of shape (m,n)\n",
    "    # Y is are the target labels (+1,-1) of shape (m,)\n",
    "    # function should return w of shape (n,)\n",
    "    \n",
    "    # your code here\n",
    "        \n",
    "def predictlogreg(X,w):\n",
    "    # X is the (testing) data of shape (m,n)\n",
    "    # w are the weights learned in logistic regression\n",
    "    # function should return Y, the predicted values of shape (m,) (all values either +1 or -1)\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "def testlogreg(X,Y,w):\n",
    "    # X and Y are the testing data\n",
    "    # w are the weights from logistic regression\n",
    "    # returns the mean squared error\n",
    "    Ypred = np.sign(predictlogreg(X,w)) ## predictlogreg output should be +1/-1, but incase they are not\n",
    "    \n",
    "    return (Ypred!=np.sign(Y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# now code to check the training and testing errors:\n",
    "wclass = learnlogreg(trainX,trainYclass)\n",
    "print('training mean classification error: ',testlogreg(trainX,trainYclass,wclass))\n",
    "print('testing mean classification error:  ',testlogreg(testX,testYclass,wclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFEEFF\">\n",
    "    <font size=+2>Part III: Feature Reduction</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #EEFFFF\">\n",
    "    In this part we are going to see if we can use <i>fewer</i> features to obtain similar results.  We will try our feature reduction (also called feature selection) method for both the regression and classification tasks.  <b>Please read this section carefully to understand how to proceed.</b>\n",
    "    <p>\n",
    "    If we know that we want $p$ features, to find the best set we would need to search over all possible subsets of $p$ features, of which there are $n \\choose p$.  However, this method is far too slow ($n \\choose p$ is far too large), so we will use an approximate method.  There are many.  This isn't necessarily the best one, but it is reasonable because we have z-score normalized our features and this is a linear problem.\n",
    "    <p>\n",
    "    The method:  Always include the constant feature (feature index 0).  Sort the other features by the absolute value of the corresponding weight when we performed learning (on the training set) using all of the features.  To get $p$ features, take the constant feature plus the $p-1$ features with the largest absolute weights (as judged by learning using all of the features).\n",
    "    <p>\n",
    "    The training set is used for everything except computing the final testing error.\n",
    "    <p>\n",
    "    So, you run learning once on all the features to get a weight vector and then sort the features (except the \"constant feature\") by the absolute value of their weights.  Then, if you want to use $p$ features, you take the constant feature plus the best $p-1$ features as judged by the absolute value of their weights.  You must train again using only these features to get a weight vector for just these features.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "    <font size=+2>Question 3:</font> <font size=+1>(3 points)</font>\n",
    "    \n",
    "Using the feature reduction method described above, compute the training and testing error for <b>linear least squares</b> as you vary the number of features. Plot these training and testing errors as a function of the number of features.  Plotting for all 1000 different values of the number of features will take too long, so only plot for multiples of 50 (that is, plot for $p=50$, $p=100$, $p=150$, ...).  Your plot should have two lines: one for the training error and one for the testing error.\n",
    "    \n",
    "You may find the `numpy` function `argsort` helpful.\n",
    "\n",
    "</div>\n",
    "   <div class=\"alert alert-success\">\n",
    "    <font size=+1>Grading</font> (to be completed by grader)<br>\n",
    "    Score: /3<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "    <font size=+2>Question 4:</font> <font size=+1>(3 points)</font>\n",
    "    <p>\n",
    "    Now do the same as Question 3, but for <b>logistic regression</b>: plot the training and testing errors as a function of the number of selected features (using $p\\in\\{50,100,150,\\dots\\}$).\n",
    "    <p>\n",
    "    Note that this will take longer.  With an efficient logistic regression learning algorithm, my solutions finish in under 5 minutes.  For debugging, you'll want to only check one (or a few) values of $p$.\n",
    "</div>\n",
    "   <div class=\"alert alert-success\">\n",
    "    <font size=+1>Grading</font> (to be completed by grader)<br>\n",
    "    Score: /3<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "    <font size=+2>Question 5:</font> <font size=+1>(3 points)</font>\n",
    "    <p>\n",
    "        Consider the results from feature selection, above.  For <b>this problem</b>...\n",
    "        <p>\n",
    "        (a) In what way(s) does reducing the number of features help?  \n",
    "        <p>\n",
    "        (b) In what way(s) does reducing the number of features hinder?\n",
    "</div>\n",
    "   <div class=\"alert alert-success\">\n",
    "    <font size=+1>Grading</font> (to be completed by grader)<br>\n",
    "    Score: /3<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answers Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS 171",
   "language": "python",
   "name": "cs171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
